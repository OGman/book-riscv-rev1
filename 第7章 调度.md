任何操作系统都有可能运行比CPU数更多的进程，所以需要对如何在进程之间分享CPU时间进行妥善安排。理想的共享应该对用户进程透明。常用的方法是在硬件CPU上复用进程，给每个进程都呈现一种假象，它拥有它自己的虚拟CPU。这一章阐述了xv6怎样实现这样的复用。

likely  illusion

# 7.1 复用

xv6中，有两种情况下，会将CPU从一个进程切换到另一个进程，从而实现复用。第一种，当进程等待设备或管道I/O完成，或等待子进程退出，或者在sleep系统调用中等待时，xv6的sleep与wakeup机制会进行切换。第二种，xv6周期性地强制切换，来处理长时间计算而不进行睡眠的进程。这种复用制造了每个进程有自己CPU的假象，正如xv6使用内存分配器和硬件页表来制造每个进程有自己的内存的假象一样。

实现复用提出了一些挑战。首先，如何从一个进程切换到另一个进程？虽然切换上下文的想法看起来很简单，但它的实现是xv6最为晦涩难懂的代码之意。其次，怎样用一种对用户进程透明的方法来强制切换？xv6使用标准技术，使用计时器中断来驱动上下文切换。第三，很多CPU可能同时在进程间切换，因此有必要制定一个锁方案来避免竞争。第四，进程的内存和其他资源必须在进程退出时释放，但进程无法独立完成所有，（例如）它不能释放自己还在被使用的内核栈。第五，多核机器的每个核必须记住正在运行的进程，这样系统调用才能操作正确进程的内核状态。最后，sleep和wakeup允许进程在等待某个事件时放弃CPU，进入睡眠，也允许别的进程唤醒之前的进程。需要注意避免竞争，不然会导致唤醒通知的丢失。xv6试着尽可能简单地解决这些问题，然而最后的代码却充满了小技巧。

opaque  nevertheless

# 7.2 代码：上下文切换

图7.1描绘了从一个用户进程切换到另一个所包含的步骤：一个用户-内核转换（系统调用或中断）到老进程的内核线程，上下文切换到当前CPU的调度线程，一个上下文切换到新进程的内核线程，一个trap返回用户层进程。xv6调度器在每个CPU上有一个专用的线程（保存的寄存器和栈），因为调度器在老进程的内核栈上运行并不安全。别的CPU核可能唤醒这个线程并运行它，在两个不同的CPU上使用同一个栈可能是灾难性的。在这个部分中，我们将研究内核线程和调度线程之间的切换机制。

从一个线程切换到另一个线程包括保存旧线程的CPU寄存器，恢复之前保存的新线程的寄存器；栈指针和程序计数器都要被保存和恢复，这说明CPU将会切换栈，并切换正在执行的代码。

swtch函数执行了内核线程切换中的保存和恢复。swtch不直接了解线程；它只是保存和恢复寄存器集合，又叫上下文。当进程需要让出CPU时，进程的内核线程调用swtch来保存自己的上下文，返回到调度器的上下文中。每个上下文的包含在context结构体中（kernel/proc.h:2），context结构体本身又被包含在进程的proc结构体或者CPU的cpu结构体中。swtch有两个参数：`struct context *old`与`struct context *new`。它把当前的寄存器保存在old中，从new中加载寄存器，然后返回。

我们来跟踪一个进程切换到调度器的过程。在第4章中我们看到一种可能性，在中断的最后，usertrap会调用yield。yield然后调用了sched，sched会调用swtch来将当前的上下文保存在p->context中，然后切换到之前保存在cpu->scheduler（kernel/proc.c:509）中的调度器上下文。

swtch（kernel/swtch.S:3）仅保存了被调者保存的寄存器；调用者保存的寄存器通过调用C代码保存在栈上（如果需要）。swtch知道context结构体中每个寄存器域的偏移。它不保存程序计数器，而是保存ra寄存器，ra记录了swtch被调用位置的返回地址。现在swtch开始从新上下文中恢复寄存器，其中的寄存器值是上一个swtch所保存的。当swtch返回时，它返回到恢复的ra寄存器所指向的指令。补充一下，它返回到新线程的栈上。

在我们的例子中，sched调用swtch来向cpu->scheduler切换，这是每个CPU的调度器上下文。这个上下文在调度器调用swtch时被保存（kernel/proc.c:475）。当我们追踪的swtch返回时，它不是返回到sched而是返回到scheduler中，而且它的栈指针指向当前CPU的调度器栈。

dedicated

# 7.3 代码：调度

上个部分研究了swtch的底层细节；现在我们将swtch视为已知，研究从一个进程的内核线程通过角度器切换到另一个进程的过程。调度器在每个CPU上以一种特殊线程的形式存在，每个都在执行scheduler函数。这个函数负责挑选下一个运行的进程。想要让出CPU的进程必须获取到自己的进程锁p->lock，释放持有的其他锁，更新自己的状态（p->state），然后调用sched。yield（kernel/proc.c:515）遵循这个习惯，与sleep和exit一样，这两个函数我们会在后面讲到。sched两次检查这些条件，然后是一个这些条件隐含的条件：因为持有锁，中断一定是被禁止的。最后，sched调用swtch来将当前的上下文保存在p->context中，切换到cpu->scheduler中的调度器上下文。swtch返回到调度器的栈，类似调度器的swtch之前的返回。调度器继续for循环，找到一个要运行的进程，切换过去，不断重复这个周期。

我们刚刚看到，xv6在调用swtch过程中持有p->lock：swtch的调用者必须已经持有这把锁，而且锁的控制权传递给了切换到的代码。这个惯例对所来说并不常见；通常获取锁的线程也要负责释放锁，这样更容易判断是否正确。在上下文切换中必须打破这个惯例，因为p->lock所保护的进程中的state和context上的不变量在swtch执行过程中是不正确的。有一个例子可以说明swtch过程中未持有p->lock会引发的问题：另一个CPU可能决定在yield后运行这个进程，将他的state设置为RUNNABLE，但在之前，swtch已经让进程停止使用自己的内核栈。结果是，两个CPU运行在同一个栈上，这是不可能正确的。

一个内核线程通常在sched中让出CPU，而且通常会切换到调度器中的同一个位置，调度器几乎总是切换到之前调用了sched的内核线程中。因此，如果在xv6切换线程的地方打印行号，将会看到一直是同一种简单的模式：（kernel/proc.c:475），（kernel/proc.c:509），（kernel/proc.c:475），（kernel/proc.c:509），等等等。在两个线程之间发生这种模式化的切换的过程有时叫做协程；在本例中，sched与scheduler彼此互为协程。

有一种情况，调度器调用的swtch不会在sched结束。当新进程开始被调度，它从forkret（kernel/proc.c:527）开始。forkret存在是为了释放p->lock；不然新的进程将以usertrapret开始。

scheduler（kernel/proc.c:457）运行一个简单的循环：找到要运行的进程，运行它直到它让出CPU，不断重复。调度器在进程表中查找可运行的进程，也就是p->state == RUNNABLE的进程。找到后，它设置每个CPU的当前进程变量c->proc，将进程标记为RUNNING，然后调用swtch来运行它（kernel/proc.c:470-475）。

有一种考虑调度代码结构的方法是这样：它强制保证每个进程的一组不变量，在不变量不正确时持有p->lock。一个不变量是如果一个进程状态为RUNNING，计时器中断yield必须能够安全地从这个进程切出去；就是说CPU寄存器必须持有进程寄存器的值（即swtch没有将它们移到context中），而且c->proc必须指向本进程。两一个不变量是如果一个进程是RUNNABLE，空闲CPU的scheduler运行它的时候必须是安全的；就是说p->context必须持有进程的寄存器（即它们当前不在真实寄存器中），没有CPU在这个进程的内核栈上运行，而且没有CPU的c->proc指向这个进程。可以看到，当p->lock被持有时，这些不变量通常是错误的。

为了保持上面这些不变量，xv6总是在一个线程获取p->lock而在另一个线程释放它，比方说在yield中获取，在scheduler中释放。一旦yield开始把正在执行的线程的state修改为RUNNABLE，锁必须保持持有状态，直到不变量恢复：最早的正确释放点在scheduler（在它自己的栈上运行）清除c->proc之后。类似的，一旦scheduler开始将进程由RUNNABLE切换到RUNNING，锁就不能被释放，知道内核线程完全运行起来（swtch之后，例如在yield中）。

p->lock也保护了其他东西：exit与wait之间的相互作用，避免唤醒丢失的流程，避免进程退出时有其他进程正在读或写它的状态所造成的竞争（例如，exit系统调用查看p->pid并设置p->killed（kernel/proc.c:611））。p->lock的不同函数是否应该分开，这是一个值得思考的问题，不管为了简单还是为了性能。

in charge of   as though   convention      makes it easier to reason about correctness    coroutines  co-routines    machinery    interplay    clarity    split up

# 7.4 代码：mycpu与myproc

xv6进程需要一个指向当前进程proc结构体的指针。在单处理器上，可以有一个全局变量执行当前的proc。在多核机器上不能这样，因为每个核执行一个不同的进程。解决这个问题的方法是利用每个核所拥有的一组寄存器；我们可以使用这些寄存器中的一个帮我们找到每个核的信息。

xv6为每个CPU维护了一个cpu结构体（kernel/proc.h:22），其中记录了当前运行在该CPU上的进程（如果有），CPU的调度器线程保存的寄存器，以及管理中断禁用需要的嵌套的自旋锁的数量。函数mycpu（kernel/proc.c:60）返回指向当前CPU的cpu结构体的指针。RISC-V会给CPU编号，每个CPU都有一个hartid。xv6保证，当运行在内核时，每个CPU的hartid都保存在其tp寄存器内。这使得mycpu可以使用tp在cpu结构体数组中找到正确的一个。

保证CPU的tp总是持有自己的hartid有点难。mstart在CPU的启动过程早期，仍在机器模式下时，设置tp寄存器（kernel/start.c:46）。usertrapret将tp保存在跳板页中，因为用户进程可能会修改tp。最后，uservec在从用户空间进入内核时恢复保存的tp（kernel/trampolie.S:70）。编译器保证从不使用tp寄存器。如果RISC-V能让xv6直接读取当前hartid的话会很方便，但这只在机器模式下允许，管理者模式不行。

cpuid与mycpu的返回值非常脆弱：如果计时器将要中断，而且引起了进程出让CPU，然后跳到另一个CPU上，那之前返回的值就不正确了。为了避免这个问题，xv6需要调用者关闭中断，知道使用完返回的cpu结构体时才能开启。

函数myproc（kernel/proc.c:68）返回当前CPU上正在运行的进程的proc结构体指针。myproc关掉中断，调用mycpu，从cpu结构体中取出当前的进程指针（c->proc），然后开启中断。myproc的返回值即使在中断开启的情况下也可以安全使用：如果计时器中断将调用进程移动到另一个CPU，这个CPU的proc结构体也还是相同的。

involved    fragile

# 7.5 睡眠与唤醒

调度与锁将进程的存在在别的进程那里隐藏起来，但到现在我们还没有什么抽象手段，能让进程进行交互。为了解决交互问题发明了很多机制。xv6使用的一种叫做睡眠唤醒，这种机制允许进程睡眠等待一个事件，而另一个进程在事件发生后唤醒它。睡眠唤醒常常被称为顺序协同或者条件同步机制。

摄像有一个同步机制，叫信号量，它负责协调生产者和消费者。信号量维护一个数字，提供两种操作。"V"操作（用于生产者）增加数字，"P"（用于消费者）等待数字变为非0，然后减少它并返回。如果只有一个生产者线程和一个消费者线程，他们在不同的CPU上执行，而且编译器没有太激进的优化，下面的实现就是正确的：

```C
struct semaphore {
  struct spinlock lock;
  int count;
};

void
V(struct semaphore *s)
{
  acquire(&s->lock);
  s->count += 1;
  release(&s->lock);
}

void
P(struct semaphore *s)
{
  while (s->count == 0)
    ;
  acquire(&s->lock);
  s->count -= 1;
  release(&s->lock);
}
```

上面的实现代价高昂。如果生产者很少工作，消费者将把大部分时间花费在自旋上，循环等待非0数的到来。消费者的CPU应该做更多生产性的工作，而不是忙等待于重复轮询s->count。避免忙等待需要一种方法，让消费者能够出让CPU，知道V操作增加count的时候再恢复。

下面来讲往这个方向努力的第一步，尽管我们会发现这还不够。假设有一对调用，sleep与wakeup，以下面的方式运行。sleep(chan)在任意值chan上睡眠，chan被称为等待频道。sleep将调用进程置为sleep状态，释放CPU给其他工作。wakup(chan)唤醒在chan上睡眠的所有进程（如果有），引起它们的sleep调用返回。如果chan上没有进程在等待，wakeup什么也不做。我们可以在semaphore的实现中使用sleep与wakup：

``` C
200 void
201 V(struct semaphore *s)
202 {
203   acquire(&s->lock);
204  s->count += 1;
205  wakeup(s);
206  release(&s->lock);
207 }

void
P(struct semaphore *s)
{
  while(s->count == 0)
    sleep(s);
  acquire(&s->lock);
  s->count -= 1;
  release(&s->lock);
}
```

P现在放弃CPU而不是自旋，这已经前进了一步。然而，事实证明，我们不能直接用这样的接口设计sleep与wakeup，众所周知的lost wake-up问题是无法避免的。假设P在212行发现s->count == 0。当P在212行与213行之间是，V在另一个CPU上运行：它将s->count改为非0，然后调用wakeup，wakeup会发现没有正在睡眠的进程，因而什么都没做。现在P继续执行213行：它调用了sleep开始睡眠。这就造成了一个问题，醒着的P在等待一个已经发生的V。除非我们走运，生产者再次调用了V，不然消费者将永远等待下去，即使cout已经是非0数。

这个问题的根源来自于V正好在错误的时间运行，违反了P仅仅在s->count == 0睡眠这个不变性。有一个错误的保护这个不变形的方法是将锁获取放在P中，这样检查count与调用sleep就变成了一个原子操作。


conceal    arbitrary
