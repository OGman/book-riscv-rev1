好的并行性能，不考虑并发的正确性，易懂的代码，在内核设计中三者兼得非常困难。直接使用锁是获得正确的最好方式，但并不总能成功。这一章重点介绍了xv6被迫以复杂方式使用锁的例子，以及xv6使用类锁但不是锁的技术。

# 9.1 锁模式

缓存项对锁来说往往是个挑战。举例来说，文件系统的块缓存（kernel/bio.c:26）保存了多达NBUFF的硬盘块的拷贝。每个给定的硬盘块在缓存中最多只有一个拷贝，这很重要；然而，不同的进程可能会在应该是同一个块的不同拷贝上制造相互冲突的修改。每个缓存的块都被保存在一个buff（kernel/buf.h:1）结构体中。buf结构体有一个锁域，用以保证同时只有一个进程使用给定硬盘块。然而，这个锁并不够：如果一个块还不在缓存中，而有两个进程同时想要使用它会怎么样？没有buf结构体（因为块还没有被缓存），因此没有什么东西可以加锁。xv6通过将一个附加锁（bcache.lock）与缓存快的身份集合联系起来，来处理这种情况。代码需要检查块是否已经被缓存（如bget（kernel/bio.c:59）），或修改缓存块集合，这必须持有bcache.lock；在那之后，代码找到了它需要的块和buf结构体，它可以释放bcache.lock，仅仅使用结构体中的锁。这是一种常见的模式：项的整个集合有一个锁，每个项又有自己的锁。

通常，获取锁的函数会释放锁。但观察事物更精确的方式，是锁在一系列需要被合并为原子操作的动作之前被获取，在所有动作完成之后被释放。如果这个序列在不同的函数，进程或者CPU中开始和结束，那锁的获取和释放也应该同步。锁的功能是强制其他的使用者等待，而不是将一段数据固定交给特定的代理。一个例子是yield中的acquire（kernel/proc.c:515），它在调度器线程中被释放而不是获取它的进程中。另一个例子是ilock中的acquiresleep（kernel/fs.c:289）；这些代码通常在读硬盘时睡眠；可能会被另一个CPU唤醒，也就意味着锁可能被别的CPU获取和释放。

释放嵌入在对象中，被锁保护的对象是个细活，因为持有锁并不足够保证释放的正确。问题出现在有别的线程正在等待获取锁来使用这个对象时；隐式的释放对象也同时释放了内部的锁，这会让正在等待的线程出故障。一个解决方法是跟踪有多少指向这个对象的引用存在，只有在最后一个引用消失时才释放对象。pipeclose是一个实例；pi->readopen与pi->writeopen跟踪了指向管道的文件描述符。

delicate    malfunction

# 9.2 类锁模式

xv6在很多地方用了引用计数或标志位作为一种软锁，来表示对象已经被分配，不能被释放或重用。进程的p->state就是这样，file、inode和buf结构体中的引用计数也是如此。尽管每种情况都还有一把锁在保护标志位或引用计数，但还是后者保护着对象不被过早地释放。

文件系统用inode的引用计数作为一种可以被多个进程持有的共享锁，其目的是壁面代码使用普通锁可能带来的死锁。举例来说，namex中的循环（kernel/fs.c：626）按顺序锁定了每个路径名元素对应的目录。然而，namex必须在循环结束释放每把锁，因为如果它持有几把锁的话，当遇到带.的路径（例如，a/./b），它会让自己死锁。如果有并行的查找包含了这个目录或者遇到..也可能发生死锁。正如第8章所说，解决方法是让循环在每一次迭代是增加目录inode的引用计数，而不是上锁。

有些数据项在不同的时候有不同的机制保护，而且有时可能被xv6的代码而不是显式的锁保护，防止其被同时访问。举例来说，当一个物理页被释放时，它被kmem.lock（kernel/kalloc.c:24）所保护。如果页在一个新进程的用户内存再次被分配，它根本不会被锁保护。取而代之的是，分配器没有将它传递给任何其他进程的事实保护它不被并行访问。新进程的拥有权有点复杂：首先，父进程在fork中分配并操作它，然后子进程使用它，接着父进程再次掌握了这些内存，并将它传给kfree。这里可以学到两点：数据对象在生命中不同的时间可能被不同的方式保护避免被并发访问，而且保护的形式可能是隐式的结构而不是显式的锁。

最后的类锁的例子是在mycpu()调用前后关闭中断（kernel/peoc.c:68）。禁止中断使得调用的代码对于计时器中断是原子的，而计时器中断可能造成上下文切换从而将进程转移到另一个CPU上。

prematurely

# 9.3 无锁

有些地方xv6共享可变数据时完全不用锁。一个是自旋锁的实现中，虽然可以将RISC-V原子指令看作是对硬件实现的锁的依赖。另一个是main.c（kernel/main.c:7）中的started变量，它被用于阻止其他CPU运行，直到CPU0完成了xv6初始化；volatile保证了编译器确实生成了负载和保存指令。第三个是proc.c中的一些对p->parent的使用（kernel/proc.c:398）（kernel/proc.c:306），当合适的锁可能产生死锁，但很明显没有其他的进程能够同时修改p->parent时。第四个例子是p->killed，它在持有p->lock（kernel/proc.c:611）时被设置，但检查时并不持有锁（kernel/trap.c:56）。

xv6还包括了一个CPU或进程写入一些数据，另一个CPU或进程读取数据，但没有特殊的锁来保护这些数据的情况。举例来说，在fork中，父进程写入子进程的用户内存页，然后子进程读取这些页；没有显式的锁保护这些页。这并不是一个严格的锁问题，因为子进程在父进程写完之后才开始运行。它可能是一个潜在的内存排序问题（见第6章），因为没有内存屏障的话，就没有理由让一个CPU看到另一个CPU的写操作。然而，因为父进程释放了锁，子进程在启动的时候获取了锁，acquire与release中的内存屏障保证了子进程的CPU能够看到父进程写的内容。

# 9.4 并行

锁的意义在于为了正确性而抑制并行。因为性能也很重要，内核设计者们常常希望有一种使用锁的方法，既保证正确又能有不错的并行性能。尽管xv6并未为高性能做系统地设计，但xv6中哪些操作能够并行执行，哪些操作可能在锁的位置冲突，还是很值得思考的。

xv6中的管道是相当不错的并行实践。每个管道都有自己的锁，所以不同的进程可以在不同CPU上并行读写不同的管道。然而，对于给定的管道来说，写入者和读取者必须相互等待对方释放锁；他们不能同时读写相同的管道。从空管道中读取时必须阻塞，但这不是因为锁。

上下文切换是另一个更复杂的粒子。两个内核线程，分别在自己的CPU商誉性，可以同时调用yield，sched和swtch，而且这些调用能够并发执行。每个线程都持有一把锁，但都是不同的锁，所以它们不需要彼此等待。但是，当处于scheduler中时，两个CPU可能在进程表中搜索RUNNABLE进程时发生锁的争用。就是说，xv6可能在上下文切换中享受到多CPU的好处，获得不错的性能，但可能并不是它能做到的最好。

另一个例子是在不同CPU上的不同进程同时调用fork。调用可能必须相互等待，等待pid_lock和kmem.lock，在进程表中查找UNUSED进程时还要等待每进程锁。另一方面，这两个正在fork的进程能完全并行地拷贝用户内存页和格式化页表页。

上面每个例子中的锁计划都满足了特定情况下的并发需求。每种情况下都可能通过更精细的设计达到更好的并行表现。是否值得依赖于细节：相关操作被调用的频率，锁争用耗费的时间有多长，有多少CPU可能会同时运行冲突的操作，是否性能瓶颈在其他的代码上。猜测给定的锁计划是否可能引起性能问题或者新的锁计划是否明显更好是很难的，所以通常都需要在现实场景下测量载。

suppressing    fairly    scheme
